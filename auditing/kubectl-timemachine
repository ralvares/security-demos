#!/usr/bin/env python3
import duckdb
import argparse
import yaml
import json
import sys
import os
from datetime import datetime, timezone

# ==============================================================================
# KUBECTL TIMEMACHINE: Forensic Digital Twin for Kubernetes
# ------------------------------------------------------------------------------
# A forensic tool that reconstructs cluster state from Audit Logs using DuckDB.
#
# FINAL VERSION (v18):
#   - Robust Argument Parsing (Flags anywhere)
#   - Crash-proof JSON handling
#   - Auto-Timezone detection
#   - Full OpenShift/K8s resource support
# ==============================================================================

def setup_args():
    # Use a single parser with nargs='*' to capture commands flexibly
    parser = argparse.ArgumentParser(
        description="kubectl-timemachine: Forensic Digital Twin for Kubernetes",
        usage="%(prog)s [flags] <command> <resource> [name]"
    )
    
    # Global Flags
    parser.add_argument("--auditlog-file", default="audit.log", help="Path to audit.log file")
    parser.add_argument("--time", help="Snapshot time (ISO8601 or YYYY-MM-DD)")
    parser.add_argument("-n", "--namespace", help="Namespace scope")
    parser.add_argument("-A", "--all-namespaces", action="store_true", help="List in all namespaces")
    parser.add_argument("-o", "--output", choices=["yaml", "json", "table", "wide"], default="table", help="Output format")
    parser.add_argument("-l", "--selector", help="Selector (label query) to filter on")
    parser.add_argument("--show-labels", action="store_true", help="Show all labels as the last column")

    # Positional Args (Captures 'get', 'pods', etc. regardless of flag position)
    parser.add_argument("args", nargs="*", help="Command and Resource")
    
    return parser

def normalize_time(time_str):
    """Parses input time. If timezone is missing, assumes LOCAL and converts to UTC."""
    if not time_str: return None
    
    # Handle YYYY-MM-DD -> End of Day
    if len(time_str) == 10 and '-' in time_str and 'T' not in time_str:
        time_str += "T23:59:59"

    try:
        # Check if user explicitly provided 'Z' (UTC)
        if time_str.endswith('Z'):
            return time_str
        
        # Assume Local Time -> Convert to UTC
        # Try formats with/without seconds
        fmt = "%Y-%m-%dT%H:%M:%S"
        if len(time_str) == 16: fmt = "%Y-%m-%dT%H:%M" # Handle "16:00"
        
        local_dt = datetime.strptime(time_str, fmt).astimezone()
        utc_dt = local_dt.astimezone(timezone.utc)
        utc_str = utc_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
        
        print(f"--- ðŸ•’ Snapshot: {time_str.replace('T', ' ')} (Local) â†’ {utc_str} (UTC) ---")
        return utc_str

    except Exception as e:
        # Fallback
        if not time_str.endswith('Z'): return time_str + 'Z'
        return time_str

def map_resource(alias):
    mapping = {
        'po': 'pods', 'pod': 'pods', 'pods': 'pods',
        'svc': 'services', 'service': 'services', 'services': 'services',
        'cm': 'configmaps', 'configmap': 'configmaps', 'configmaps': 'configmaps',
        'sa': 'serviceaccounts', 'serviceaccount': 'serviceaccounts', 'serviceaccounts': 'serviceaccounts',
        'ns': 'namespaces', 'namespace': 'namespaces', 'namespaces': 'namespaces',
        'no': 'nodes', 'node': 'nodes', 'nodes': 'nodes',
        'se': 'secrets', 'secret': 'secrets', 'secrets': 'secrets',
        'pv': 'persistentvolumes', 'persistentvolume': 'persistentvolumes', 'persistentvolumes': 'persistentvolumes',
        'pvc': 'persistentvolumeclaims', 'persistentvolumeclaim': 'persistentvolumeclaims', 'persistentvolumeclaims': 'persistentvolumeclaims',
        'deploy': 'deployments', 'deployment': 'deployments', 'deployments': 'deployments',
        'ds': 'daemonsets', 'daemonset': 'daemonsets', 'daemonsets': 'daemonsets',
        'sts': 'statefulsets', 'statefulset': 'statefulsets', 'statefulsets': 'statefulsets',
        'rs': 'replicasets', 'replicaset': 'replicasets', 'replicasets': 'replicasets',
        'job': 'jobs', 'jobs': 'jobs',
        'cj': 'cronjobs', 'cronjob': 'cronjobs', 'cronjobs': 'cronjobs',
        'ing': 'ingresses', 'ingress': 'ingresses', 'ingresses': 'ingresses',
        'rt': 'routes', 'route': 'routes', 'routes': 'routes',
        'netpol': 'networkpolicies', 'networkpolicy': 'networkpolicies',
        'vm': 'virtualmachines', 'virtualmachine': 'virtualmachines', 'virtualmachines': 'virtualmachines',
        'vmi': 'virtualmachineinstances', 'virtualmachineinstance': 'virtualmachineinstances', 'virtualmachineinstances': 'virtualmachineinstances',
        'all': 'all'
    }
    return mapping.get(alias.lower(), alias.lower())

def is_cluster_scoped(resource):
    return resource in ['namespaces', 'nodes', 'persistentvolumes', 'clusterrolebindings', 'clusterroles']

def safe_parse_json(obj):
    """Recursively attempts to parse JSON to handle double-encoding"""
    if isinstance(obj, dict): return obj
    if not isinstance(obj, str): return {}
    try:
        parsed = json.loads(obj)
        # Handle double-encoded strings: "{\"kind\":...}" -> {"kind":...}
        if isinstance(parsed, str):
            try: return json.loads(parsed)
            except: return {}
        return parsed
    except: return {}

def calculate_age(creation_ts, snapshot_time_utc):
    if not creation_ts: return "?"
    try:
        fmt = "%Y-%m-%dT%H:%M:%SZ"
        if "." in creation_ts: fmt = "%Y-%m-%dT%H:%M:%S.%fZ"
        created = datetime.strptime(creation_ts, fmt).replace(tzinfo=timezone.utc)
        
        if snapshot_time_utc:
            now = datetime.strptime(snapshot_time_utc, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=timezone.utc)
        else:
            now = datetime.now(timezone.utc)

        delta = now - created
        if delta.total_seconds() < 0: return "0s" 

        if delta.days > 0: return f"{delta.days}d"
        hours, remainder = divmod(delta.seconds, 3600)
        minutes, _ = divmod(remainder, 60)
        if hours > 0: return f"{hours}h{minutes}m"
        return f"{minutes}m"
    except: return "?"

def extract_status(obj):
    obj = safe_parse_json(obj)
    status = obj.get('status', {})
    if isinstance(status, str): return status
    
    if 'printableStatus' in status: return status['printableStatus']
    if 'phase' in status: return status['phase']
    if 'conditions' in status and isinstance(status['conditions'], list):
        for cond in reversed(status['conditions']):
            if cond.get('status') == "True": return cond.get('type')
    if 'loadBalancer' in status or 'ingress' in status: return "Admitted"
    return "-"

def get_path(d, *keys, default=None):
    current = d
    for k in keys:
        if not isinstance(current, dict): return default
        current = current.get(k)
        if current is None: return default
    return current

def extract_pod_ip(obj):
    ip = get_path(obj, 'status', 'podIP')
    if ip: return ip
    
    # OpenShift OVN
    try:
        ovn_annot = get_path(obj, 'metadata', 'annotations', 'k8s.ovn.org/pod-networks')
        if ovn_annot:
            ovn_data = json.loads(ovn_annot)
            if 'default' in ovn_data:
                ips = ovn_data['default'].get('ip_addresses', [])
                if ips: return ips[0].split('/')[0]
    except: pass
    
    # Multus
    try:
        cni_annot = get_path(obj, 'metadata', 'annotations', 'k8s.v1.cni.cncf.io/network-status')
        if cni_annot:
            cni_data = json.loads(cni_annot)
            if isinstance(cni_data, list) and len(cni_data) > 0:
                return cni_data[0].get('ips', ['<none>'])[0]
    except: pass
    return '<none>'

def extract_labels(obj):
    obj = safe_parse_json(obj)
    labels = get_path(obj, 'metadata', 'labels')
    if not labels or not isinstance(labels, dict): return "" 
    return ",".join([f"{k}={v}" for k, v in sorted(labels.items())])

def extract_wide_info(resource, raw_obj):
    """Extracts extra columns for -o wide with Safety Checks"""
    obj = safe_parse_json(raw_obj)
    if not obj: return []
    info = []
    
    if resource == 'pods':
        ip = extract_pod_ip(obj)
        node = get_path(obj, 'spec', 'nodeName', default='<none>')
        info = [ip, node]
    elif resource == 'services':
        svc_type = get_path(obj, 'spec', 'type', default='ClusterIP')
        cluster_ip = get_path(obj, 'spec', 'clusterIP', default='<none>')
        selector_dict = get_path(obj, 'spec', 'selector', default={})
        selector = ",".join([f"{k}={v}" for k, v in selector_dict.items()]) if isinstance(selector_dict, dict) and selector_dict else "<none>"
        info = [svc_type, cluster_ip, selector]
    elif resource == 'nodes':
        os_img = get_path(obj, 'status', 'nodeInfo', 'osImage', default='<none>')
        kernel = get_path(obj, 'status', 'nodeInfo', 'kernelVersion', default='<none>')
        runtime = get_path(obj, 'status', 'nodeInfo', 'containerRuntimeVersion', default='<none>')
        info = [os_img, kernel, runtime]
    elif resource == 'deployments':
        containers = get_path(obj, 'spec', 'template', 'spec', 'containers', default=[])
        images = ",".join([c.get('image', '') for c in containers if isinstance(c, dict)])
        selector_dict = get_path(obj, 'spec', 'selector', 'matchLabels', default={})
        selector = ",".join([f"{k}={v}" for k, v in selector_dict.items()]) if isinstance(selector_dict, dict) and selector_dict else "<none>"
        info = [images, selector]
    elif resource == 'virtualmachineinstances':
        node = get_path(obj, 'status', 'nodeName', default='<none>')
        interfaces = get_path(obj, 'status', 'interfaces', default=[])
        ip = '<none>'
        if isinstance(interfaces, list) and len(interfaces) > 0:
            ip = interfaces[0].get('ipAddress', '<none>')
        info = [ip, node]
    return info

def build_query(log_file, resource, name, namespace, all_ns, time_limit, selector):
    time_sql = f"AND requestReceivedTimestamp <= '{time_limit}'" if time_limit else ""
    name_sql = f"AND name = '{name}'" if name else ""
    
    label_sql = ""
    if selector:
        parts = selector.split(',')
        for part in parts:
            if '=' in part:
                k, v = part.split('=', 1)
                label_sql += f" AND json_extract_string(obj, '$.metadata.labels.\"{k}\"') = '{v}'"

    ns_sql = ""
    cluster_scoped = is_cluster_scoped(resource)
    
    if not cluster_scoped:
        if not all_ns:
            if namespace: ns_sql = f"AND namespace = '{namespace}'"
            else: ns_sql = "AND namespace = 'default'"

    partition_by = "PARTITION BY name" if cluster_scoped else "PARTITION BY namespace, name"

    query = f"""
    WITH raw_stream AS (
        SELECT 
            requestReceivedTimestamp as ts,
            verb,
            json_extract_string(objectRef, '$.resource') as resource,
            json_extract_string(objectRef, '$.namespace') as namespace,
            json_extract_string(objectRef, '$.name') as name,
            COALESCE(responseObject, requestObject) as obj
        FROM read_json_auto('{log_file}', ignore_errors=true)
        WHERE verb IN ('create', 'update', 'patch', 'delete')
          AND resource = '{resource}'
          {time_sql}
          AND (responseObject IS NOT NULL OR requestObject IS NOT NULL)
    ),
    latest_state AS (
        SELECT *,
            ROW_NUMBER() OVER ({partition_by} ORDER BY ts DESC) as rn
        FROM raw_stream
        WHERE name IS NOT NULL
    )
    SELECT namespace, name, obj 
    FROM latest_state 
    WHERE rn = 1 AND verb != 'delete'
    {ns_sql} {name_sql} {label_sql}
    ORDER BY namespace, name
    """
    return query

def main():
    parser = setup_args()
    args = parser.parse_args()
    
    if not args.args or len(args.args) < 1:
        parser.print_help()
        sys.exit(1)

    command = args.args[0]
    if command != "get":
        print(f"Error: Unknown command '{command}'. Only 'get' is supported.")
        sys.exit(1)

    if len(args.args) < 2:
        print("Error: You must specify a resource type (e.g. pods).")
        sys.exit(1)

    resource_input = args.args[1]
    name_input = args.args[2] if len(args.args) > 2 else None

    if not os.path.exists(args.auditlog_file):
        print(f"Error: File '{args.auditlog_file}' not found."); sys.exit(1)

    args.time = normalize_time(args.time)

    req_res = map_resource(resource_input)
    if req_res == 'all':
        resources_to_fetch = ['pods', 'services', 'daemonsets', 'deployments', 'replicasets', 'statefulsets', 'jobs', 'cronjobs', 'routes', 'ingresses', 'virtualmachines', 'virtualmachineinstances']
    else:
        resources_to_fetch = [req_res]

    con = duckdb.connect(database=':memory:')
    
    for resource in resources_to_fetch:
        sql = build_query(args.auditlog_file, resource, name_input, args.namespace, args.all_namespaces, args.time, args.selector)
        try: results = con.execute(sql).fetchall()
        except: continue
        if not results: continue

        if len(resources_to_fetch) > 1: print(f"\n--- {resource.upper()} ---")

        if args.output == "yaml":
            for row in results:
                payload = safe_parse_json(row[2])
                print("---")
                print(yaml.dump(payload))
        elif args.output == "json":
            for row in results: print(row[2])
        else: # Table/Wide
            cluster_scoped = is_cluster_scoped(resource)
            rows_to_print = []
            
            headers = ["NAMESPACE", "NAME", "AGE", "STATUS"]
            if cluster_scoped: headers = ["NAME", "AGE", "STATUS"]
            
            if args.output == "wide":
                if resource == 'pods': headers.extend(["IP", "NODE"])
                elif resource == 'services': headers.extend(["TYPE", "CLUSTER-IP", "SELECTOR"])
                elif resource == 'nodes': headers.extend(["OS-IMAGE", "KERNEL-VERSION", "CONTAINER-RUNTIME"])
                elif resource == 'deployments': headers.extend(["IMAGES", "SELECTOR"])
                elif resource == 'virtualmachineinstances': headers.extend(["IP", "NODE"])

            if args.show_labels: headers.append("LABELS")

            for row in results:
                ns_val = row[0] if row[0] else "-"
                name_val = row[1]
                if len(resources_to_fetch) > 1: display_name = f"{map_resource(resource)}/{name_val}"
                else: display_name = name_val

                payload = safe_parse_json(row[2])
                created = get_path(payload, 'metadata', 'creationTimestamp')
                age = calculate_age(created, args.time)
                status = extract_status(payload)
                
                if cluster_scoped: row_data = [display_name, age, status]
                else: row_data = [ns_val, display_name, age, status]
                
                if args.output == "wide": row_data.extend(extract_wide_info(resource, payload))
                if args.show_labels: row_data.append(extract_labels(payload))
                
                rows_to_print.append(row_data)

            widths = [len(h) for h in headers]
            for row in rows_to_print:
                for i, val in enumerate(row):
                    if i < len(widths): widths[i] = max(widths[i], len(str(val)))

            header_fmt = "  ".join([f"{{:<{w}}}" for w in widths])
            if args.output in ["table", "wide"]:
                print(header_fmt.format(*headers))
                for row in rows_to_print: print(header_fmt.format(*row))

if __name__ == "__main__":
    main()